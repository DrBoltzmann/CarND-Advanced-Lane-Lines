{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import glob\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load camera calibration data\n",
    "pickle_data = pickle.load(open(\"camera_cal/calibration_pickle.p\", \"rb\"))\n",
    "mtx = pickle_data['mtx']\n",
    "dist = pickle_data['dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    if orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def color_threshold(image, sthresh=(0, 255), vthresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    s_channel = hls[:, :, 2]\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= sthresh[0]) & (s_channel < sthresh[1])] = 1\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    v_channel = hsv[:, :, 2]\n",
    "    v_binary = np.zeros_like(v_channel)\n",
    "    v_binary[(v_channel >= vthresh[0]) & (v_channel < vthresh[1])] = 1\n",
    "\n",
    "    output = np.zeros_like(s_channel)\n",
    "    output[(s_binary == 1) & (v_binary == 1)] = 1\n",
    "    return output\n",
    "\n",
    "def thresholdImage(image):\n",
    "    gradx = abs_sobel_thresh(image, orient='x', thresh=(12,100))\n",
    "    grady = abs_sobel_thresh(image, orient='y', thresh=(25,100))\n",
    "    c_binary = color_threshold(image, sthresh=(100, 255), vthresh=(50, 255))\n",
    "    combined = np.zeros_like(c_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | (c_binary == 1)] = 255\n",
    "    return combined\n",
    "\n",
    "# Do thresholding\n",
    "#threshold_images = [thresholdImage(i) for i in undistort_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTransformImages(imgs, titles, dots):\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    for i, img in enumerate(imgs):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        plt.title(titles[i])\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.plot(dots[i][0][0], dots[i][0][1], 'r.', ms=12) # top right\n",
    "        plt.plot(dots[i][1][0], dots[i][1][1], 'r.', ms=12) # bottom right\n",
    "        plt.plot(dots[i][2][0], dots[i][2][1], 'r.', ms=12) # bottom left\n",
    "        plt.plot(dots[i][3][0], dots[i][3][1], 'r.', ms=12) # top left\n",
    "    plt.show()\n",
    "    \n",
    "def transformImage(image, src, dst):\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "# Transformation coordinates\n",
    "src = np.float32([[693, 455],[1075, 700],[230, 700],[588, 455]])\n",
    "dst = np.float32([[950, 0],[950, 720],[250, 720],[250, 0]])\n",
    "\n",
    "# Do transformation\n",
    "#transformed_images = [transformImage(i,src,dst) for i in threshold_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWindowCentroids(img, window_width, rows, margin=40, last_centroids=[0, 0], DEBUG=False):\n",
    "    window_centroids = []\n",
    "    window_height = int(img.shape[0] / rows)\n",
    "    half_image_width = int(img.shape[1]/2)\n",
    "    left_lane_x = last_centroids[0]\n",
    "    right_lane_x = last_centroids[1]\n",
    "    left_start = 0 if left_lane_x == 0 else left_lane_x - margin\n",
    "    left_end = half_image_width - 1 if left_lane_x == 0 else left_lane_x + margin\n",
    "    right_start = half_image_width if right_lane_x == 0 else right_lane_x - margin\n",
    "    right_end = img.shape[1] - 1 if right_lane_x == 0 else right_lane_x + margin\n",
    "    \n",
    "    for i, y_window_pos in enumerate(range(img.shape[0], 0, -window_height)):\n",
    "        row_image = img[y_window_pos - window_height: y_window_pos]\n",
    "        conv_signal = np.convolve(np.ones(window_width), np.sum(row_image, axis=0))\n",
    "            \n",
    "        if window_centroids:\n",
    "            left_lane_x, right_lane_x = window_centroids[-1]\n",
    "            left_start = left_lane_x - margin\n",
    "            left_end = left_lane_x + margin\n",
    "            right_start = right_lane_x - margin\n",
    "            right_end = right_lane_x + margin\n",
    "\n",
    "        if np.max(conv_signal[left_start:left_end]) > 0:\n",
    "            left_lane_x = np.argmax(conv_signal[left_start:left_end]) + left_start\n",
    "        \n",
    "        if np.max(conv_signal[right_start:right_end]) > 0:\n",
    "            right_lane_x = np.argmax(conv_signal[right_start:right_end]) + right_start\n",
    "        \n",
    "        window_centroids.append((left_lane_x,right_lane_x))\n",
    "\n",
    "    return np.array(window_centroids) - window_width / 2\n",
    "\n",
    "def updateMask(mask, window_width, rows, image_shape, center, level):\n",
    "    window_height = image_shape[0] / rows\n",
    "    height_start = int(image_shape[0] - (level + 1) * window_height)\n",
    "    height_end = int(image_shape[0] - level * window_height)\n",
    "    width_start = max(0, int(center - window_width / 2))\n",
    "    width_end = min(int(center + window_width / 2), image_shape[1])\n",
    "    mask[height_start:height_end, width_start:width_end] = 255\n",
    "\n",
    "def getWindowOverlayImage(image, window_centroids, window_width, rows):\n",
    "    zeros = np.zeros_like(image)\n",
    "    mask = np.zeros_like(image)\n",
    "    \n",
    "    # Go through each level and update window mask\n",
    "    for i, centroid in enumerate(window_centroids):\n",
    "        updateMask(mask, window_width, rows, image.shape, centroid[0], i)\n",
    "        updateMask(mask, window_width, rows, image.shape, centroid[1], i)\n",
    "\n",
    "    # Make window pixels green\n",
    "    windows = np.array(cv2.merge((zeros, np.array(mask), zeros)), np.uint8)\n",
    "    # Overlay the orignal road image with window results\n",
    "    return cv2.addWeighted(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB), 0.5, windows, 0.5, 0.0)\n",
    "\n",
    "def getLaneImages(images, window_width, window_rows):\n",
    "    output_images = []\n",
    "    output_centroids = []\n",
    "    for image in images:\n",
    "        centroids = findWindowCentroids(image, window_width, window_rows)\n",
    "        output_images.append(getWindowOverlayImage(image, centroids, window_width, window_rows))\n",
    "        output_centroids.append(centroids)\n",
    "    return output_images, output_centroids\n",
    "\n",
    "# Detect lanes on all birds eye test images\n",
    "#detected_lane_images, detected_centroids = getLaneImages(transformed_images, 50, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "def textOverlay(img, res_yvals, yvals, leftx, left_fitx, right_fitx):\n",
    "    curve_fit_cr = np.polyfit(np.array(res_yvals, np.float32)*ym_per_pix, np.array(leftx, np.float32) * xm_per_pix, 2)\n",
    "    curverad = ((1 + (2 * curve_fit_cr[0] * yvals[-1] * ym_per_pix + curve_fit_cr[1])**2)**1.5) / np.absolute(2*curve_fit_cr[0])\n",
    "    camera_center = (left_fitx[-1] + right_fitx[-1]) / 2\n",
    "    center_diff = (camera_center-img.shape[1]/2) * xm_per_pix\n",
    "    side_pos = 'left'\n",
    "    if center_diff <= 0:\n",
    "        side_pos = 'right'\n",
    "    cv2.putText(img, 'Radius of Curvature = ' + str(round(curverad, 3)) + 'm', (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "        (255,255,255), 2)\n",
    "    cv2.putText(img, 'Vehicle is ' + str(abs(round(center_diff,3))) + 'm ' + side_pos + ' of center', (50,100), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    \n",
    "\n",
    "def drawLane(img, centroids, transformed):\n",
    "    img = img.copy()\n",
    "    leftx = [i[0] for i in centroids]\n",
    "    rightx = [i[1] for i in centroids]\n",
    "    \n",
    "    yvals = range(img.shape[0])\n",
    "    res_yvals = np.arange(img.shape[0]-(img.shape[0]/16), 0, -img.shape[0] / len(centroids) )\n",
    "    \n",
    "    # f(x) = Ax**2 + Bx + C\n",
    "    left_fit = np.polyfit(res_yvals, leftx, 2)\n",
    "    left_fitx = np.array(left_fit[0] * yvals * yvals +  left_fit[1] * yvals + left_fit[2], np.int32)\n",
    "\n",
    "    right_fit = np.polyfit(res_yvals, rightx, 2)\n",
    "    right_fitx = np.array(right_fit[0] * yvals * yvals +  right_fit[1] * yvals + right_fit[2], np.int32)\n",
    "    \n",
    "    textOverlay(img, res_yvals, yvals, leftx, left_fitx, right_fitx)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warp_zero = np.zeros_like(transformed).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, yvals]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, yvals])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    # Combine the result with the original image\n",
    "\n",
    "    return cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "\n",
    "#lane_images = [drawLane(i, c, t) for i, c, t in zip(undistort_images, detected_centroids, transformed_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./videos/out_project_video.mp4\n",
      "[MoviePy] Writing video ./videos/out_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [02:29<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./videos/out_project_video.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_left_lane = []\n",
    "max_left_lane = []\n",
    "min_right_lane = []\n",
    "max_right_lane = []\n",
    "\n",
    "def processImage(image):\n",
    "    img_undistorted = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    img_thresholded = thresholdImage(img_undistorted)\n",
    "    img_transformed = transformImage(img_thresholded, src, dst)\n",
    "    centroids = findWindowCentroids(img_transformed, 50, 8)\n",
    "    \n",
    "    min_left_lane.append(centroids[:,0].min())\n",
    "    max_left_lane.append(centroids[:,0].max())\n",
    "    min_right_lane.append(centroids[:,1].min())\n",
    "    max_right_lane.append(centroids[:,1].max())\n",
    "    \n",
    "    return drawLane(img_undistorted, centroids, img_transformed)\n",
    "    \n",
    "input_video = './project_video.mp4'\n",
    "output_video = './videos/out_project_video.mp4'\n",
    "\n",
    "clip = VideoFileClip(input_video)\n",
    "video_clip = clip.fl_image(processImage)\n",
    "video_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = np.array(cv2.merge((zeros_channel, template, zero_channel)), np.uint8)\n",
    "warpage = np.array(cv2.merge((warped, warped, warped)), np.uint8)\n",
    "resutls = cv2.addWeighted(warpage, 1, template, 0.5, 0.0)\n",
    "\n",
    "# Fit lane boundaries to the left, right, and center positions\n",
    "\n",
    "yvals = range(0, warped.shape[0])\n",
    "\n",
    "res_yvals = np.arrange(warped.shape[0] - (window_height / 2), 0, -window_height)\n",
    "\n",
    "left_fit = np.polyfit(res_yvals, leftx, 2)\n",
    "left_fitx = left_fit[0] * yvals**2 + left_fit[1] * yvals + left_fit[2]\n",
    "left_fitx = np.array(left_fitx, np.int32)\n",
    "\n",
    "right_fit = np.polyfit(res_yvals, rightx, 2)\n",
    "right_fitx = right_fit[0] * yvals**2 + right_fit[1] * yvals + right_fit[2]\n",
    "right_fitx = np.array(right_fitx, np.int32)\n",
    "\n",
    "left_lane = np.array(list(zip(np.concatenate((left_fitx - window_width / 2, left_fitx[::-1]) + window_width / 2), axis = 0), np.concatenate((yvals))))\n",
    "right_lane = np.array(list(zip(np.concatenate((right_fitx - window_width / 2, right_fitx[::-1]) + window_width / 2), axis = 0), np.concatenate((yvals))))\n",
    "middle_marker = np.array(list(zip(np.concatenate((right_fitx - window_width / 2, left_fitx[::-1]) + window_width / 2), axis = 0), np.concatenate((yvals))))\n",
    "\n",
    "road = np.zeros_like(img)\n",
    "road_bkg = np.zeros_like(img)\n",
    "\n",
    "cv2.fillPoly(road, [left_lane], color = [255, 0, 0])\n",
    "cv2.fillPoly(road, [right_lane], color = [0, 0, 255])\n",
    "cv2.fillPoly(road_bkg, [left_lane], color = [255, 255, 255])\n",
    "cv2.fillPoly(road_bkg, [right_lane], color = [255, 255, 255])\n",
    "\n",
    "road_warped = cv2.warpPerspective(road, Minv, img_size, flags = cv2.INTER_LINEAR)\n",
    "road_warped_bkg = cv2.warpPerspective(road, Minv, img_size, flags = cv2.INTER_LINEAR)\n",
    "\n",
    "base = cv2.addWeighted(img, 1.0, road_warped_bkg, 1.0, 0.0)\n",
    "result = cv2.addWeighted(base, 1.0, road_warped, 1.0, 0.0)\n",
    "\n",
    "ym_per_pix = 30 / 720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7 / 700 # meters per pixel in x dimension\n",
    "\n",
    "curve_fit_cr = np.polyfit(np.arry(res_yvals, np.float32) * (ym_per_pix), np.array(leftx, np.float32) * xm_per_pix, 2)\n",
    "curverad = ((1 + (2 * curve_fit_cr[0] * y_vals[-1] * ym_per_pix + curve_fit_cr[1])**2)**1.5) / np.absolute(2 * curve_fit_cr[0])\n",
    "\n",
    "\n",
    "# Calculate the offset of the car on the road\n",
    "camera_center = (left_fitx[-1] + right_fitx[-1]) / 2\n",
    "center_diff = (camera_center-warped.shape[1] / 2) * xm_per_pix\n",
    "\n",
    "side_pos = 'left'\n",
    "\n",
    "if center_diff <= 0:\n",
    "    side_pos = 'right'\n",
    "    \n",
    "# draw the text showing curvatue, offset, and speed\n",
    "# Annotate image with lane curvature estimates\n",
    "cv2.putText(result, 'Left Lane Radius: ' + str(round(curverad, 3)) + '(m)', (50,50), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 2)\n",
    "cv2.putText(result, 'Vehicle Position: ' + str(abs(round(center_diff, 3))) + '(m)' + sid_pos + 'of center', (50,100), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "\n",
    "write_name = './output_images/tracked' + str(idx) + '.jpg'\n",
    "cv2.imwrite(write_name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in images from a folder and perform an operation on them\n",
    "\n",
    "images = glob.glob('./test_images/test*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    result = img\n",
    "    \n",
    "    write_name = './test_images/tracked' + str(idx) + '.jpg'\n",
    "    cv2.imwrite(write_name,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# Read in a thresholded image\n",
    "warped = mpimg.imread('warped_example.jpg')\n",
    "# window settings\n",
    "window_width = 50 \n",
    "window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "margin = 100 # How much to slide left and right for searching\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(image, window_width, window_height, margin):\n",
    "    \n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(image[int(3*image.shape[0]/4):,:int(image.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(image[int(3*image.shape[0]/4):,int(image.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(image.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(image.shape[0]/window_height)):\n",
    "\t    # convolve the window into the vertical slice of the image\n",
    "\t    image_layer = np.sum(image[int(image.shape[0]-(level+1)*window_height):int(image.shape[0]-level*window_height),:], axis=0)\n",
    "\t    conv_signal = np.convolve(window, image_layer)\n",
    "\t    # Find the best left centroid by using past left center as a reference\n",
    "\t    # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "\t    offset = window_width/2\n",
    "\t    l_min_index = int(max(l_center+offset-margin,0))\n",
    "\t    l_max_index = int(min(l_center+offset+margin,image.shape[1]))\n",
    "\t    l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "\t    # Find the best right centroid by using past right center as a reference\n",
    "\t    r_min_index = int(max(r_center+offset-margin,0))\n",
    "\t    r_max_index = int(min(r_center+offset+margin,image.shape[1]))\n",
    "\t    r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "\t    # Add what we found for that layer\n",
    "\t    window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "\n",
    "# If we found any window centers\n",
    "if len(window_centroids) > 0:\n",
    "\n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "\n",
    "    # Go through each level and draw the windows \t\n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "\t    l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "\t    r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "\t    # Add graphic points from window mask here to total pixels found \n",
    "\t    l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "\t    r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    warpage= np.dstack((warped, warped, warped))*255 # making the original road pixels 3 color channels\n",
    "    output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    " \n",
    "# If no window centers found, just display orginal road image\n",
    "else:\n",
    "    output = np.array(cv2.merge((warped,warped,warped)),np.uint8)\n",
    "\n",
    "# Display the final results\n",
    "plt.imshow(output)\n",
    "plt.title('window fitting results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines(binary_warped, left_fit, right_fit):\n",
    "    \n",
    "    # Define positions for all non zero pixels\n",
    "    nonzero = binary_wapred.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])    \n",
    "    \n",
    "    margin = 100\n",
    "    \n",
    "    # left_curverad, right_curverad, center_dist = (0, 0, 0)\n",
    "    \n",
    "    # Choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > (left_fit[0] * (nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0] * (nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin))) \n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[l_lane_inds]\n",
    "    lefty = nonzeroy[l_lane_inds] \n",
    "    rightx = nonzerox[r_lane_inds]\n",
    "    righty = nonzeroy[r_lane_inds]\n",
    "    \n",
    "    left_fit,left_res,_,_,_ = np.polyfit(lefty, leftx, 2, full=True)\n",
    "    right_fit,right_res,_,_,_ = np.polyfit(righty, rightx, 2, full=True)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "    \n",
    "    left_fitx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty**2 + right_fit[1] * ploty + right_fit[2]\n",
    "    \n",
    "    y_eval = warped_binary.shape[0]    \n",
    "    \n",
    "    # Compute convsions between pixels and real-world dimensions\n",
    "    ym_per_pix = 30 / 720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty * ym_per_pix, left_fitx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * ym_per_pix, right_fitx * xm_per_pix, 2)\n",
    "    \n",
    "    #left_fit_cr = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    #right_fit_cr = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)    \n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2 * right_fit_cr[0])\n",
    "    \n",
    "    # Compute car position\n",
    "    m_car = binary_warped.shape[1] / 2\n",
    "    m_lane = (left_fitx[0] + right_fitx[0]) / 2\n",
    "    offset_right_from_center_m = (m_lane - m_car) * xm_per_pix\n",
    "    \n",
    "    # Compute radius of curvature in meters\n",
    "    avg_radius_meters = np.mean([left_curverad, right_curverad])\n",
    "    \n",
    "    #return left_curverad, right_curverad, left_fitx, right_fitx, offset_right_from_center_m\n",
    "    return left_fit, right_fit, np.sqrt(left_fit[1]/len(leftx)), np.sqrt(right_fit[1]/len(rightx)), left_curverad, right_curverad, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test1 = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "dist_pickle = pickle.load(open(\"camera_cal/calibration_pickle.p\", \"rb\"))\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "#undistorted1 = undistort(img_test1)\n",
    "undistorted1 = cv2.undistort(img_test1, mtx, dist, None, mtx)\n",
    "binary_warped1 = topdown(pipeline_color(undistorted1, s_thresh=s_thresh, sx_thresh=sx_thresh, sobel_kernel=9))\n",
    "\n",
    "l_fit, r_fit, l_res, r_res, l_curverad, r_curverad, _ = sliding_windows(binary_warped1)\n",
    "\n",
    "annotated_test = draw_lane(undistorted1, binary_warped1, l_fit, r_fit, _, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a color threshold function with HLS and HSV and test it.\n",
    "\n",
    "def color_lab(img):\n",
    "    \n",
    "    LAB = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "    LAB_L = LAB[:,:,0]\n",
    "    LAB_A = LAB[:,:,1]\n",
    "    LAB_B = LAB[:,:,2]\n",
    "    \n",
    "    return LAB, LAB_L, LAB_A, LAB_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_lab(img, thresh=(190,255)):\n",
    "    \n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "    \n",
    "    lab_b = lab[:,:,2]\n",
    "    \n",
    "    # don't normalize if there are no yellows in the image\n",
    "    if np.max(lab_b) > 150:\n",
    "        lab_b = lab_b * (255 / np.max(lab_b))\n",
    "    \n",
    "    # 2) Apply a threshold to the L channel\n",
    "    binary_output = np.zeros_like(lab_b)\n",
    "    binary_output[((lab_b > thresh[0]) & (lab_b <= thresh[1]))] = 1\n",
    "    \n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
