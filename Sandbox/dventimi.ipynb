{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4744fc5d4b16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;31m# #+RESULTS:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m \u001b[0mwarp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munwarp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_warpers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mundistort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_images/straight_lines2.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;31m# #+RESULTS:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4744fc5d4b16>\u001b[0m in \u001b[0;36mget_warpers\u001b[1;34m(corrected_image)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_warpers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrected_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeasure_warp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrected_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMinv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMinv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4744fc5d4b16>\u001b[0m in \u001b[0;36mmeasure_warp\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mcid1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpl_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'button_press_event'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mcid2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpl_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'close_event'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m     \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPerspectiveTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masfarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masfarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[0mMinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPerspectiveTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masfarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masfarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mstart_event_loop\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   2412\u001b[0m         \u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mimplemented\u001b[0m \u001b[0monly\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbackends\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mGUIs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2413\u001b[0m         \"\"\"\n\u001b[1;32m-> 2414\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2416\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstop_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# https://github.com/dventimi/CarND-Advanced-Lane-Lines/blob/master/lanelines.py\n",
    "\n",
    "# Setup\n",
    "\n",
    "from collections import deque\n",
    "from itertools import groupby, islice, zip_longest, cycle, filterfalse\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.widgets import Button\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "from moviepy.editor import VideoFileClip\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import cProfile\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "# Camera Calibration\n",
    "\n",
    "def measure_distortion(calibration_files):\n",
    "    files = calibration_files\n",
    "    objp = np.zeros((9*6,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "    stage1 = map(lambda x: (x,), cycle(files))\n",
    "    stage2 = map(lambda x: x + (mpimg.imread(x[0]),), stage1)\n",
    "    stage3 = map(lambda x: x + (cv2.findChessboardCorners(cv2.cvtColor(x[1], cv2.COLOR_RGB2GRAY), (9,6)),), stage2)\n",
    "    stage4 = map(lambda x: x + (cv2.drawChessboardCorners(np.copy(x[1]), (9,6), *(x[2][::-1])),), stage3)\n",
    "    filenames,images,corners,annotated_images = zip(*filter(lambda x: x[2][0], islice(stage4, len(files))))\n",
    "    _,imgpoints = zip(*corners)\n",
    "    objpoints = [objp for i in range(len(imgpoints))]\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, list(islice(stage2,1))[0][1].shape[:2:][::-1], None, None)\n",
    "    return mtx, dist, zip(filenames, annotated_images)\n",
    "\n",
    "# Distortion Correction\n",
    "\n",
    "def get_undistorter(calibration_files):\n",
    "    mtx,dist,annotated_images = measure_distortion(calibration_files)\n",
    "    return lambda x: cv2.undistort(x, mtx, dist, None, mtx), annotated_images\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "undistort,annotated_images = get_undistorter(glob.glob(\"camera_cal/*.jpg\"))\n",
    "fig = plt.figure()\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(4,4), axes_pad=0.0)\n",
    "\n",
    "for p in zip(annotated_images, grid):\n",
    "    p[1].imshow(p[0][1])\n",
    "\n",
    "fig.savefig(\"output_images/annotated_calibration_images.jpg\")\n",
    "\n",
    "# #+RESULTS:\n",
    "#       #+begin_example\n",
    "\n",
    "#       ... ... <matplotlib.image.AxesImage object at 0x7fb71aa7c320>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb719dc6048>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb719e9bf28>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb71a97bbe0>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb719ea9ba8>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb719ebd748>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb7190a0668>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb71a5fcb38>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb7190bf2e8>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb71905c2b0>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb71a653128>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb7190515f8>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb719089cc0>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb71901bdd8>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb719030710>\n",
    "#       <matplotlib.image.AxesImage object at 0x7fb71a14b2e8>\n",
    "# #+end_example\n",
    "\n",
    "#       #+ATTR_HTML: :width 800px\n",
    "#       [[file:output_images/annotated_calibration_images.jpg]]\n",
    "\n",
    "def visualize(filename, a):\n",
    "    fig, axes = plt.subplots(2,3,figsize=(24,12),subplot_kw={'xticks':[],'yticks':[]})\n",
    "    fig.subplots_adjust(hspace=0.03, wspace=0.05)\n",
    "    for p in zip(sum(axes.tolist(),[]), a):\n",
    "        p[0].imshow(p[1],cmap='gray')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "visualize(\"output_images2/test_images.jpg\",\n",
    "          (mpimg.imread(f) for f in cycle(glob.glob(\"test_images/test*.jpg\"))))\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "#       #+ATTR_HTML: :width 800px\n",
    "#       [[file:output_images/test_images.jpg]]\n",
    "\n",
    "visualize(\"output_images2/undistorted_test_images.jpg\",\n",
    "          (undistort(mpimg.imread(f)) for f in cycle(glob.glob(\"test_images/test*.jpg\"))))\n",
    "\n",
    "# Perspective Measurement\n",
    "\n",
    "def measure_warp(img):\n",
    "    top = 0\n",
    "    bottom = img.shape[0]\n",
    "    def handler(e):\n",
    "        if len(src)<4:\n",
    "            plt.axhline(int(e.ydata), linewidth=2, color='r')\n",
    "            plt.axvline(int(e.xdata), linewidth=2, color='r')\n",
    "            src.append((int(e.xdata),int(e.ydata)))\n",
    "        if len(src)==4:\n",
    "            dst.extend([(300,bottom),(300,top),(980,top),(980,bottom)])\n",
    "    was_interactive = matplotlib.is_interactive()\n",
    "    if not matplotlib.is_interactive():\n",
    "        plt.ion()\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(img)\n",
    "    global src\n",
    "    global dst\n",
    "    src = []\n",
    "    dst = []\n",
    "    cid1 = fig.canvas.mpl_connect('button_press_event', handler)\n",
    "    cid2 = fig.canvas.mpl_connect('close_event', lambda e: e.canvas.stop_event_loop())\n",
    "    fig.canvas.start_event_loop(timeout=-1)\n",
    "    M = cv2.getPerspectiveTransform(np.asfarray(src, np.float32), np.asfarray(dst, np.float32))\n",
    "    Minv = cv2.getPerspectiveTransform(np.asfarray(dst, np.float32), np.asfarray(src, np.float32))\n",
    "    matplotlib.interactive(was_interactive)\n",
    "    return M, Minv\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "def get_warpers(corrected_image):\n",
    "    M, Minv = measure_warp(corrected_image)\n",
    "    return lambda x: cv2.warpPerspective(x, M, x.shape[:2][::-1], flags=cv2.INTER_LINEAR), lambda x: cv2.warpPerspective(x, Minv, x.shape[:2][::-1], flags=cv2.INTER_LINEAR), M, Minv\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "warp,unwarp,M,Minv = get_warpers(undistort(mpimg.imread(\"test_images/straight_lines2.jpg\")))\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "#       #+ATTR_HTML: :width 800px\n",
    "#       [[file:output_images/figure_3-1.png]]\n",
    "\n",
    "#       #+ATTR_HTML: :width 800px\n",
    "#       [[file:output_images/figure_3-2.png]]\n",
    "\n",
    "#       #+ATTR_HTML: :width 800px\n",
    "#       [[file:output_images/figure_3-3.png]]\n",
    "\n",
    "#       #+ATTR_HTML: :width 800px\n",
    "#       [[file:output_images/figure_3-4.png]]\n",
    "\n",
    "visualize(\"output_images2/warped_undistorted_test_images.jpg\",\n",
    "          (warp(undistort(mpimg.imread(f))) for f in cycle(glob.glob(\"test_images/test*.jpg\"))))\n",
    "\n",
    "# Gradient and Color Thresholds\n",
    "\n",
    "def scale(img, factor=255.0):\n",
    "    scale_factor = np.max(img)/factor\n",
    "    return (img/scale_factor).astype(np.uint8)\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "def derivative(img, sobel_kernel=3):\n",
    "    derivx = np.absolute(cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    derivy = np.absolute(cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    gradmag = np.sqrt(derivx**2 + derivy**2)\n",
    "    absgraddir = np.arctan2(derivy, derivx)\n",
    "    return scale(derivx), scale(derivy), scale(gradmag), absgraddir\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "def grad(img, k1=3, k2=15):\n",
    "    _,_,g,_ = derivative(img, sobel_kernel=k1)\n",
    "    _,_,_,p = derivative(img, sobel_kernel=k2)\n",
    "    return g,p\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "def hls_select(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    h = hsv[:,:,0]\n",
    "    l = hsv[:,:,1]\n",
    "    s = hsv[:,:,2]\n",
    "    return h,l,s\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "def rgb_select(img):\n",
    "    rgb = img\n",
    "    r = rgb[:,:,0]\n",
    "    g = rgb[:,:,1]\n",
    "    b = rgb[:,:,2]\n",
    "    return r,g,b\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "def threshold(img, thresh_min=0, thresh_max=255):\n",
    "    binary_output = np.zeros_like(img)\n",
    "    binary_output[(img >= thresh_min) & (img <= thresh_max)] = 1\n",
    "    return binary_output\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "land = lambda *x: np.logical_and.reduce(x)\n",
    "lor = lambda *x: np.logical_or.reduce(x)\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "def highlight(img):\n",
    "    r,g,b = rgb_select(img)\n",
    "    h,l,s = hls_select(img)\n",
    "    o01 = threshold(r, 200, 255)\n",
    "    o02 = threshold(g, 200, 255)\n",
    "    o03 = threshold(s, 200, 255)\n",
    "    return scale(lor(land(o01,o02),o03))\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "visualize(\"output_images2/binary_undistorted_test_images.jpg\",\n",
    "          (highlight(undistort(mpimg.imread(f))) for f in cycle(glob.glob(\"test_images/test*.jpg\"))))\n",
    "\n",
    "# Perspective Transform\n",
    "\n",
    "visualize(\"output_images2/warped_binary_undistorted_images.jpg\",\n",
    "          (warp(highlight(undistort(mpimg.imread(f)))) for f in cycle(glob.glob(\"test_images/test*.jpg\"))))\n",
    "\n",
    "# Lane-Finding\n",
    "\n",
    "def detect_lines_sliding_window(warped_binary):\n",
    "    # Assuming you have created a warped binary image called \"warped_binary\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(warped_binary[warped_binary.shape[0]/2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((warped_binary, warped_binary, warped_binary))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(warped_binary.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = warped_binary.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = warped_binary.shape[0] - (window+1)*window_height\n",
    "        win_y_high = warped_binary.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit,left_res,_,_,_ = np.polyfit(lefty, leftx, 2, full=True)\n",
    "    right_fit,right_res,_,_,_ = np.polyfit(righty, rightx, 2, full=True)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, warped_binary.shape[0]-1, warped_binary.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    out_img[ploty.astype('int'),left_fitx.astype('int')] = [0, 255, 255]\n",
    "    out_img[ploty.astype('int'),right_fitx.astype('int')] = [0, 255, 255]\n",
    "    y_eval = warped_binary.shape[0]\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    return left_fit, right_fit, np.sqrt(left_fit[1]/len(leftx)), np.sqrt(right_fit[1]/len(rightx)), left_curverad, right_curverad, out_img\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "visualize(\"output_images2/detected_lines_test_images.jpg\",\n",
    "          (detect_lines_sliding_window(warp(highlight(undistort(mpimg.imread(f)))))[6] for f in cycle(glob.glob(\"test_images/test*.jpg\"))))\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "#       #+ATTR_HTML: :width 800px\n",
    "#       [[file:output_images/detected_lines_test_images.jpg]]\n",
    "\n",
    "def detect_lines(warped_binary, left_fit, right_fit):\n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = warped_binary.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit,left_res,_,_,_ = np.polyfit(lefty, leftx, 2, full=True)\n",
    "    right_fit,right_res,_,_,_ = np.polyfit(righty, rightx, 2, full=True)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, warped_binary.shape[0]-1, warped_binary.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    y_eval = warped_binary.shape[0]\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    return left_fit, right_fit, np.sqrt(left_fit[1]/len(leftx)), np.sqrt(right_fit[1]/len(rightx)), left_curverad, right_curverad, None\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "def draw_lane(undistorted, warped_binary, l_fit, r_fit, l_rad, r_rad, unwarp):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, warped_binary.shape[0]-1, warped_binary.shape[0])\n",
    "    l_fitx = l_fit[0]*ploty**2 + l_fit[1]*ploty + l_fit[2]\n",
    "    r_fitx = r_fit[0]*ploty**2 + r_fit[1]*ploty + r_fit[2]\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([l_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([r_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    # Draw the lane onto the warped_binary blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    # newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    newwarp = unwarp(color_warp)\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistorted, 1, newwarp, 0.3, 0)\n",
    "    # Annotate image with lane curvature estimates\n",
    "    cv2.putText(result, \"L. Curvature: %.2f km\" % (l_rad/1000), (50,50), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 2)\n",
    "    cv2.putText(result, \"R. Curvature: %.2f km\" % (r_rad/1000), (50,80), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 2)\n",
    "    # Annotate image with position estimate\n",
    "    cv2.putText(result, \"C. Position: %.2f m\" % ((np.average((l_fitx + r_fitx)/2) - warped_binary.shape[1]//2)*3.7/700), (50,110), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 2)\n",
    "    return result\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "visualize(\"output_images2/drawn_lanes_test_images.jpg\", \n",
    "          (get_processor(1)(mpimg.imread(f)) for f in cycle(glob.glob(\"test_images/test*.jpg\"))))\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "#       #+ATTR_HTML: :width 800px\n",
    "#       [[file:output_images/drawn_lanes_test_images.jpg]]\n",
    "\n",
    "def get_processor(nbins=10):\n",
    "    bins = nbins\n",
    "    l_params = deque(maxlen=bins)\n",
    "    r_params = deque(maxlen=bins)\n",
    "    l_radius = deque(maxlen=bins)\n",
    "    r_radius = deque(maxlen=bins)\n",
    "    weights = np.arange(1,bins+1)/bins\n",
    "    def process_image(img0):\n",
    "        undistorted = undistort(img0)\n",
    "        warped_binary = warp(highlight(undistorted))\n",
    "        l_fit, r_fit, l_res, r_res, l_curverad, r_curverad, _ = detect_lines_sliding_window(warped_binary) if len(l_params)==0 else detect_lines(warped_binary,np.average(l_params,0,weights[-len(l_params):]), np.average(r_params,0,weights[-len(l_params):]))\n",
    "        l_params.append(l_fit)\n",
    "        r_params.append(r_fit)\n",
    "        l_radius.append(l_curverad)\n",
    "        r_radius.append(r_curverad)\n",
    "        annotated_image = draw_lane(undistorted,\n",
    "                                    warped_binary,\n",
    "                                    np.average(l_params,0,weights[-len(l_params):]),\n",
    "                                    np.average(r_params,0,weights[-len(l_params):]),\n",
    "                                    np.average(l_radius,0,weights[-len(l_params):]),\n",
    "                                    np.average(r_radius,0,weights[-len(l_params):]),\n",
    "                                    unwarp)\n",
    "        return annotated_image\n",
    "    return process_image\n",
    "\n",
    "# #+RESULTS:\n",
    "\n",
    "in_clip = VideoFileClip(\"project_video.mp4\")\n",
    "out_clip = in_clip.fl_image(get_processor(5))\n",
    "cProfile.run('out_clip.write_videofile(\"output_images2/project_output.mp4\", audio=False)', 'restats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
